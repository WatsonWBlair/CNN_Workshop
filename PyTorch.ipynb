{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "This notebook guides the user through implementing a CNN using PyTorch. The architecture and data set should match those present in the TensorFlow notebook.\n",
    "\n",
    "## Steps:\n",
    "- Select data-set\n",
    "- Define Architecture\n",
    "- Instantiate CNN\n",
    "- Train and Test\n",
    "- Output Convolution layers and results\n",
    "- thoroughly display test results and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Transpose (this PyTorch tutorial)[https://medium.com/@myringoleMLGOD/simple-convolutional-neural-network-cnn-for-dummies-in-pytorch-a-step-by-step-guide-6f4109f6df80] into this notebook.\n",
    "\n",
    "\n",
    "Update the tutorial to use (this bird classification dataset)[https://www.kaggle.com/datasets/rahmasleam/bird-speciees-dataset/data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters (Kernels):\n",
    "\n",
    "    Filters are small matrices that slide over the input image and perform element-wise multiplications followed by summation. Each filter is designed to detect a specific feature in the input image.\n",
    "    For example, a filter might detect horizontal edges, vertical edges, or more complex textures.\n",
    "    The output of applying a filter to the input image is called a feature map or activation map. If you have multiple filters, you will get multiple feature maps.\n",
    "\n",
    "Stride:\n",
    "\n",
    "    Stride is the step size with which the filter moves across the input image.\n",
    "    A stride of 1 means the filter moves one pixel at a time, both horizontally and vertically.\n",
    "    A larger stride reduces the size of the feature map because the filter skips more pixels. For instance, a stride of 2 means the filter moves two pixels at a time, effectively down-sampling the feature map.\n",
    "\n",
    "Padding:\n",
    "\n",
    "    Padding involves adding extra pixels around the input image’s border. These extra pixels are typically set to zero (zero-padding).\n",
    "    Padding ensures that the filter fits properly over the image, especially at the edges. Without padding, the feature map’s size reduces after each convolution operation.\n",
    "    For example, if you have a 5x5 input image and a 3x3 filter with no padding, the resulting feature map will be 3x3. With padding of 1, the feature map remains the same size as the input.\n",
    "\n",
    "Feature Map:\n",
    "\n",
    "    A feature map is the output of a convolutional layer after applying filters to the input image.\n",
    "    Each feature map corresponds to a different filter and captures different features from the input.\n",
    "    Stacking multiple feature maps together forms a multi-channel output that serves as the input for the next layer.\n",
    "\n",
    "Pooling Layers\n",
    "\n",
    "Pooling layers reduce the spatial dimensions of the feature maps, which helps in making the network computationally efficient and reducing overfitting. There are two main types of pooling:\n",
    "\n",
    "    Max Pooling:\n",
    "\n",
    "    Max pooling takes the maximum value from each patch of the feature map.\n",
    "    For example, in a 2x2 max pooling operation, the maximum value from each 2x2 block of the feature map is taken to create a new, smaller feature map.\n",
    "    This operation reduces the size of the feature map by half, both horizontally and vertically, but retains the most prominent features.\n",
    "\n",
    "    Average Pooling:\n",
    "\n",
    "    Average pooling takes the average value from each patch of the feature map.\n",
    "    Similar to max pooling, but instead of the maximum value, it takes the average value from each block.\n",
    "    This can be useful in different contexts, though max pooling is more common in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Module\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        \"\"\"\n",
    "        Define the layers of the convolutional neural network.\n",
    "\n",
    "        Parameters:\n",
    "            in_channels: int\n",
    "                The number of channels in the input image. For MNIST, this is 1 (grayscale images).\n",
    "            num_classes: int\n",
    "                The number of classes we want to predict, in our case 10 (digits 0 to 9).\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__() # Add an explanation of what super() does for us here and Link to documentation.\n",
    "\n",
    "        # First convolutional layer: 1 input channel, 8 output channels, 3x3 kernel, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer: 2x2 window, stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Second convolutional layer: 8 input channels, 16 output channels, 3x3 kernel, stride 1, padding 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # Fully connected layer: 16*7*7 input features (after two 2x2 poolings), 10 output features (num_classes)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the neural network.\n",
    "        TODO: Add a description of what a forward pass is.\n",
    "\n",
    "        Parameters:\n",
    "            x: torch.Tensor\n",
    "                The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor\n",
    "                The output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "        x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)            # Apply fully connected layer\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if Available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model-Specific Variables\n",
    "input_size = 784  # 28x28 pixels (not directly used in CNN)\n",
    "num_classes = 10  # digits 0-9\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10  # Reduced for demonstration purposes\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize Model and Optimizer\n",
    "model = CNN(in_channels=1, num_classes=num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and Split Data\n",
    "train_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Move data and targets to the device (GPU/CPU)\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass: compute the model output\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward pass: compute the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimization step: update the model parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "# TODO: Expand this section to include ROC, Confusion Matrix, ect...\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Checks the accuracy of the model on the given dataset loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader: DataLoader\n",
    "            The DataLoader for the dataset to check accuracy on.\n",
    "        model: nn.Module\n",
    "            The neural network model.\n",
    "    \"\"\"\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for x, y in loader: # update to have a descriptive name for x nd y\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)  # Get the index of the max log-probability\n",
    "            num_correct += (predictions == y).sum()  # Count correct predictions\n",
    "            num_samples += predictions.size(0)  # Count total samples\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = float(num_correct) / float(num_samples) * 100\n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {accuracy:.2f}%\")\n",
    "    \n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "# Final accuracy check on training and test sets\n",
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(test_loader, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
